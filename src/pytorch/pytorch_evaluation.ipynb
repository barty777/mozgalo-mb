{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from data import crop_upper_part, BinaryDataset\n",
    "from model import SqueezeModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED_TEST_DATASET = '/home/filipgulan/Downloads/set/test_set'\n",
    "CPU_CORES = 8\n",
    "BATCH_SIZE = 32\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS REQUIRES THE master branch of the `torchivsion` package\n",
    "def data_transformations(input_shape, crop_perc = 0.5):\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(lambda x: crop_upper_part(np.array(x), crop_perc)),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def var(tensor, volatile=False):\n",
    "    if USE_GPU:\n",
    "        tensor = tensor.cuda(0)\n",
    "    return Variable(tensor, volatile=volatile)\n",
    "\n",
    "def test_sigmoid(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for i, test_batch in enumerate(test_loader):\n",
    "        test_x, test_y = (var(test_batch[0], volatile=True),\n",
    "                          var(test_batch[1], volatile=True))\n",
    "        logit = model(test_x)\n",
    "        \n",
    "        softmax = F.sigmoid(logit).cpu().data.numpy()\n",
    "        ground_truths.extend(test_y.cpu().data.numpy())\n",
    "        \n",
    "        for act in softmax:\n",
    "            predictions.append(act)\n",
    "       \n",
    "        print('Predicting batch {}/{}'.format(i + 1, len(test_loader)), end=\"\\r\", flush=True)\n",
    "        \n",
    "    return np.array(predictions), np.array(ground_truths)\n",
    "\n",
    "\n",
    "def test_softmax(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for i, test_batch in enumerate(test_loader):\n",
    "        test_x, test_y = (var(test_batch[0], volatile=True),\n",
    "                          var(test_batch[1], volatile=True))\n",
    "        logit = model(test_x)\n",
    "        \n",
    "        softmax = F.softmax(logit, dim=0).cpu().data.numpy()\n",
    "        ground_truths.extend(test_y.cpu().data.numpy())\n",
    "        \n",
    "        for act in softmax:\n",
    "            predictions.append(act)\n",
    "       \n",
    "        print('Predicting batch {}/{}'.format(i + 1, len(test_loader)), end=\"\\r\", flush=True)\n",
    "        \n",
    "    return np.array(predictions), np.array(ground_truths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: ./outdir/CenterLossAvg_epoch_18-valLoss_0.01228-valAcc_0.99669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gulan_filip/mozgalo-mb/src/pytorch/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/home/gulan_filip/mozgalo-mb/src/pytorch/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Load sigmoid model\n",
    "NUM_CLASSES = 2\n",
    "MODEL_PATH = \"./outdir/CenterLossAvg_epoch_18-valLoss_0.01228-valAcc_0.99669\"\n",
    "\n",
    "model_sigmoid = SqueezeModel(fine_tune=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "model_sigmoid.load_state_dict(torch.load(MODEL_PATH, map_location=lambda storage, loc: storage))\n",
    "print(\"Loaded model from:\", MODEL_PATH)\n",
    "model_sigmoid.eval()\n",
    "\n",
    "if USE_GPU:\n",
    "    model_sigmoid.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: ./outdir/25_class_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gulan_filip/mozgalo-mb/src/pytorch/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/home/gulan_filip/mozgalo-mb/src/pytorch/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Load softmax model\n",
    "NUM_CLASSES = 25\n",
    "MODEL_PATH = \"./outdir/25_class_model\"\n",
    "\n",
    "model_softmax = SqueezeModel(fine_tune=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "model_softmax.load_state_dict(torch.load(MODEL_PATH, map_location=lambda storage, loc: storage))\n",
    "print(\"Loaded model from:\", MODEL_PATH)\n",
    "model_softmax.eval()\n",
    "\n",
    "if USE_GPU:\n",
    "    model_softmax.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = data_transformations((3, 370, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/filipgulan/college/test/Other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5bf1325e77f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mANNOTATED_TEST_DATASET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m test_dataset_loader_binary = torch.utils.data.DataLoader(test_dataset_binary,\n\u001b[1;32m      3\u001b[0m                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     num_workers=CPU_CORES)\n",
      "\u001b[0;32m~/college/mozgalo-mb/src/pytorch/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, images_dir, other_folder_name, transform)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         self.neg_images = [os.path.join(negative_folder, img) for img in\n\u001b[0;32m---> 62\u001b[0;31m                            os.listdir(negative_folder) if not img.startswith(\".\")]\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_images\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/filipgulan/college/test/Other'"
     ]
    }
   ],
   "source": [
    "test_dataset_binary = BinaryDataset(images_dir=ANNOTATED_TEST_DATASET, transform=test_transform)\n",
    "test_dataset_loader_binary = torch.utils.data.DataLoader(test_dataset_binary,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=CPU_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/filipgulan/Downloads/set/test_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6d9074971e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mANNOTATED_TEST_DATASET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m test_dataset_loader_softmax = torch.utils.data.DataLoader(test_dataset_softmax,\n\u001b[1;32m      3\u001b[0m                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     num_workers=CPU_CORES)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m    176\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[1;32m    177\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                           target_transform=target_transform)\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/filipgulan/Downloads/set/test_set'"
     ]
    }
   ],
   "source": [
    "test_dataset_softmax = datasets.ImageFolder(root=ANNOTATED_TEST_DATASET, transform=test_transform)\n",
    "test_dataset_loader_softmax = torch.utils.data.DataLoader(test_dataset_softmax,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=CPU_CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other vs. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch 313/313\r"
     ]
    }
   ],
   "source": [
    "pred, true = test_sigmoid(model_sigmoid, test_dataset_loader_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.99      0.97      5009\n",
      "        1.0       0.99      0.95      0.97      4991\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thr = 0.5\n",
    "sigmoid_classes = np.copy(pred)\n",
    "sigmoid_classes[pred > thr] = 1\n",
    "sigmoid_classes[pred <= thr] = 0\n",
    "\n",
    "report = metrics.classification_report(true, sigmoid_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 class softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c89b7e2b29eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset_loader_softmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-43c2fcde3128>\u001b[0m in \u001b[0;36mtest_softmax\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mground_truths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "pred, true = test_softmax(model_softmax, test_dataset_loader_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.argmax(pred)\n",
    "report = metrics.classification_report(correct, true)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting results for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Albertsons',\n",
       " 1: 'BJs',\n",
       " 2: 'CVSPharmacy',\n",
       " 3: 'Costco',\n",
       " 4: 'FredMeyer',\n",
       " 5: 'Frys',\n",
       " 6: 'HEB',\n",
       " 7: 'HarrisTeeter',\n",
       " 8: 'HyVee',\n",
       " 9: 'JewelOsco',\n",
       " 10: 'KingSoopers',\n",
       " 11: 'Kroger',\n",
       " 12: 'Meijer',\n",
       " 13: 'Publix',\n",
       " 14: 'Safeway',\n",
       " 15: 'SamsClub',\n",
       " 16: 'ShopRite',\n",
       " 17: 'Smiths',\n",
       " 18: 'StopShop',\n",
       " 19: 'Target',\n",
       " 20: 'Walgreens',\n",
       " 21: 'Walmart',\n",
       " 22: 'Wegmans',\n",
       " 23: 'WholeFoodsMarket',\n",
       " 24: 'WinCoFoods'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class indices when OTher is present\n",
    "labels = {'Albertsons': 0,\n",
    " 'BJs': 1,\n",
    " 'CVSPharmacy': 2,\n",
    " 'Costco': 3,\n",
    " 'FredMeyer': 4,\n",
    " 'Frys': 5,\n",
    " 'HEB': 6,\n",
    " 'HarrisTeeter': 7,\n",
    " 'HyVee': 8,\n",
    " 'JewelOsco': 9,\n",
    " 'KingSoopers': 10,\n",
    " 'Kroger': 11,\n",
    " 'Meijer': 12,\n",
    " 'Publix': 13,\n",
    " 'Safeway': 14,\n",
    " 'SamsClub': 15,\n",
    " 'ShopRite': 16,\n",
    " 'Smiths': 17,\n",
    " 'StopShop': 18,\n",
    " 'Target': 19,\n",
    " 'Walgreens': 20,\n",
    " 'Walmart': 21,\n",
    " 'Wegmans': 22,\n",
    " 'WholeFoodsMarket': 23,\n",
    " 'WinCoFoods': 24}\n",
    "class_dict = {v: k for k, v in labels.items()}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/10000\n",
      "Processed 10/10000\n",
      "Processed 20/10000\n",
      "Processed 30/10000\n",
      "Processed 40/10000\n",
      "Processed 50/10000\n",
      "Processed 60/10000\n",
      "Processed 70/10000\n",
      "Processed 80/10000\n",
      "Processed 90/10000\n",
      "Processed 100/10000\n",
      "Processed 110/10000\n",
      "Processed 120/10000\n",
      "Processed 130/10000\n",
      "Processed 140/10000\n",
      "Processed 150/10000\n",
      "Processed 160/10000\n",
      "Processed 170/10000\n",
      "Processed 180/10000\n",
      "Processed 190/10000\n",
      "Processed 200/10000\n",
      "Processed 210/10000\n",
      "Processed 220/10000\n",
      "Processed 230/10000\n",
      "Processed 240/10000\n",
      "Processed 250/10000\n",
      "Processed 260/10000\n",
      "Processed 270/10000\n",
      "Processed 280/10000\n",
      "Processed 290/10000\n",
      "Processed 300/10000\n",
      "Processed 310/10000\n",
      "Processed 320/10000\n",
      "Processed 330/10000\n",
      "Processed 340/10000\n",
      "Processed 350/10000\n",
      "Processed 360/10000\n",
      "Processed 370/10000\n",
      "Processed 380/10000\n",
      "Processed 390/10000\n",
      "Processed 400/10000\n",
      "Processed 410/10000\n",
      "Processed 420/10000\n",
      "Processed 430/10000\n",
      "Processed 440/10000\n",
      "Processed 450/10000\n",
      "Processed 460/10000\n",
      "Processed 470/10000\n",
      "Processed 480/10000\n",
      "Processed 490/10000\n",
      "Processed 500/10000\n",
      "Processed 510/10000\n",
      "Processed 520/10000\n",
      "Processed 530/10000\n",
      "Processed 540/10000\n",
      "Processed 550/10000\n",
      "Processed 560/10000\n",
      "Processed 570/10000\n",
      "Processed 580/10000\n",
      "Processed 590/10000\n",
      "Processed 600/10000\n",
      "Processed 610/10000\n",
      "Processed 620/10000\n",
      "Processed 630/10000\n",
      "Processed 640/10000\n",
      "Processed 650/10000\n",
      "Processed 660/10000\n",
      "Processed 670/10000\n",
      "Processed 680/10000\n",
      "Processed 690/10000\n",
      "Processed 700/10000\n",
      "Processed 710/10000\n",
      "Processed 720/10000\n",
      "Processed 730/10000\n",
      "Processed 740/10000\n",
      "Processed 750/10000\n",
      "Processed 760/10000\n",
      "Processed 770/10000\n",
      "Processed 780/10000\n",
      "Processed 790/10000\n",
      "Processed 800/10000\n",
      "Processed 810/10000\n",
      "Processed 820/10000\n",
      "Processed 830/10000\n",
      "Processed 840/10000\n",
      "Processed 850/10000\n",
      "Processed 860/10000\n",
      "Processed 870/10000\n",
      "Processed 880/10000\n",
      "Processed 890/10000\n",
      "Processed 900/10000\n",
      "Processed 910/10000\n",
      "Processed 920/10000\n",
      "Processed 930/10000\n",
      "Processed 940/10000\n",
      "Processed 950/10000\n",
      "Processed 960/10000\n",
      "Processed 970/10000\n",
      "Processed 980/10000\n",
      "Processed 990/10000\n",
      "Processed 1000/10000\n",
      "Processed 1010/10000\n",
      "Processed 1020/10000\n",
      "Processed 1030/10000\n",
      "Processed 1040/10000\n",
      "Processed 1050/10000\n",
      "Processed 1060/10000\n",
      "Processed 1070/10000\n",
      "Processed 1080/10000\n",
      "Processed 1090/10000\n",
      "Processed 1100/10000\n",
      "Processed 1110/10000\n",
      "Processed 1120/10000\n",
      "Processed 1130/10000\n",
      "Processed 1140/10000\n",
      "Processed 1150/10000\n",
      "Processed 1160/10000\n",
      "Processed 1170/10000\n",
      "Processed 1180/10000\n",
      "Processed 1190/10000\n",
      "Processed 1200/10000\n",
      "Processed 1210/10000\n",
      "Processed 1220/10000\n",
      "Processed 1230/10000\n",
      "Processed 1240/10000\n",
      "Processed 1250/10000\n",
      "Processed 1260/10000\n",
      "Processed 1270/10000\n",
      "Processed 1280/10000\n",
      "Processed 1290/10000\n",
      "Processed 1300/10000\n",
      "Processed 1310/10000\n",
      "Processed 1320/10000\n",
      "Processed 1330/10000\n",
      "Processed 1340/10000\n",
      "Processed 1350/10000\n",
      "Processed 1360/10000\n",
      "Processed 1370/10000\n",
      "Processed 1380/10000\n",
      "Processed 1390/10000\n",
      "Processed 1400/10000\n",
      "Processed 1410/10000\n",
      "Processed 1420/10000\n",
      "Processed 1430/10000\n",
      "Processed 1440/10000\n",
      "Processed 1450/10000\n",
      "Processed 1460/10000\n",
      "Processed 1470/10000\n",
      "Processed 1480/10000\n",
      "Processed 1490/10000\n",
      "Processed 1500/10000\n",
      "Processed 1510/10000\n",
      "Processed 1520/10000\n",
      "Processed 1530/10000\n",
      "Processed 1540/10000\n",
      "Processed 1550/10000\n",
      "Processed 1560/10000\n",
      "Processed 1570/10000\n",
      "Processed 1580/10000\n",
      "Processed 1590/10000\n",
      "Processed 1600/10000\n",
      "Processed 1610/10000\n",
      "Processed 1620/10000\n",
      "Processed 1630/10000\n",
      "Processed 1640/10000\n",
      "Processed 1650/10000\n",
      "Processed 1660/10000\n",
      "Processed 1670/10000\n",
      "Processed 1680/10000\n",
      "Processed 1690/10000\n",
      "Processed 1700/10000\n",
      "Processed 1710/10000\n",
      "Processed 1720/10000\n",
      "Processed 1730/10000\n",
      "Processed 1740/10000\n",
      "Processed 1750/10000\n",
      "Processed 1760/10000\n",
      "Processed 1770/10000\n",
      "Processed 1780/10000\n",
      "Processed 1790/10000\n",
      "Processed 1800/10000\n",
      "Processed 1810/10000\n",
      "Processed 1820/10000\n",
      "Processed 1830/10000\n",
      "Processed 1840/10000\n",
      "Processed 1850/10000\n",
      "Processed 1860/10000\n",
      "Processed 1870/10000\n",
      "Processed 1880/10000\n",
      "Processed 1890/10000\n",
      "Processed 1900/10000\n",
      "Processed 1910/10000\n",
      "Processed 1920/10000\n",
      "Processed 1930/10000\n",
      "Processed 1940/10000\n",
      "Processed 1950/10000\n",
      "Processed 1960/10000\n",
      "Processed 1970/10000\n",
      "Processed 1980/10000\n",
      "Processed 1990/10000\n",
      "Processed 2000/10000\n",
      "Processed 2010/10000\n",
      "Processed 2020/10000\n",
      "Processed 2030/10000\n",
      "Processed 2040/10000\n",
      "Processed 2050/10000\n",
      "Processed 2060/10000\n",
      "Processed 2070/10000\n",
      "Processed 2080/10000\n",
      "Processed 2090/10000\n",
      "Processed 2100/10000\n",
      "Processed 2110/10000\n",
      "Processed 2120/10000\n",
      "Processed 2130/10000\n",
      "Processed 2140/10000\n",
      "Processed 2150/10000\n",
      "Processed 2160/10000\n",
      "Processed 2170/10000\n",
      "Processed 2180/10000\n",
      "Processed 2190/10000\n",
      "Processed 2200/10000\n",
      "Processed 2210/10000\n",
      "Processed 2220/10000\n",
      "Processed 2230/10000\n",
      "Processed 2240/10000\n",
      "Processed 2250/10000\n",
      "Processed 2260/10000\n",
      "Processed 2270/10000\n",
      "Processed 2280/10000\n",
      "Processed 2290/10000\n",
      "Processed 2300/10000\n",
      "Processed 2310/10000\n",
      "Processed 2320/10000\n",
      "Processed 2330/10000\n",
      "Processed 2340/10000\n",
      "Processed 2350/10000\n",
      "Processed 2360/10000\n",
      "Processed 2370/10000\n",
      "Processed 2380/10000\n",
      "Processed 2390/10000\n",
      "Processed 2400/10000\n",
      "Processed 2410/10000\n",
      "Processed 2420/10000\n",
      "Processed 2430/10000\n",
      "Processed 2440/10000\n",
      "Processed 2450/10000\n",
      "Processed 2460/10000\n",
      "Processed 2470/10000\n",
      "Processed 2480/10000\n",
      "Processed 2490/10000\n",
      "Processed 2500/10000\n",
      "Processed 2510/10000\n",
      "Processed 2520/10000\n",
      "Processed 2530/10000\n",
      "Processed 2540/10000\n",
      "Processed 2550/10000\n",
      "Processed 2560/10000\n",
      "Processed 2570/10000\n",
      "Processed 2580/10000\n",
      "Processed 2590/10000\n",
      "Processed 2600/10000\n",
      "Processed 2610/10000\n",
      "Processed 2620/10000\n",
      "Processed 2630/10000\n",
      "Processed 2640/10000\n",
      "Processed 2650/10000\n",
      "Processed 2660/10000\n",
      "Processed 2670/10000\n",
      "Processed 2680/10000\n",
      "Processed 2690/10000\n",
      "Processed 2700/10000\n",
      "Processed 2710/10000\n",
      "Processed 2720/10000\n",
      "Processed 2730/10000\n",
      "Processed 2740/10000\n",
      "Processed 2750/10000\n",
      "Processed 2760/10000\n",
      "Processed 2770/10000\n",
      "Processed 2780/10000\n",
      "Processed 2790/10000\n",
      "Processed 2800/10000\n",
      "Processed 2810/10000\n",
      "Processed 2820/10000\n",
      "Processed 2830/10000\n",
      "Processed 2840/10000\n",
      "Processed 2850/10000\n",
      "Processed 2860/10000\n",
      "Processed 2870/10000\n",
      "Processed 2880/10000\n",
      "Processed 2890/10000\n",
      "Processed 2900/10000\n",
      "Processed 2910/10000\n",
      "Processed 2920/10000\n",
      "Processed 2930/10000\n",
      "Processed 2940/10000\n",
      "Processed 2950/10000\n",
      "Processed 2960/10000\n",
      "Processed 2970/10000\n",
      "Processed 2980/10000\n",
      "Processed 2990/10000\n",
      "Processed 3000/10000\n",
      "Processed 3010/10000\n",
      "Processed 3020/10000\n",
      "Processed 3030/10000\n",
      "Processed 3040/10000\n",
      "Processed 3050/10000\n",
      "Processed 3060/10000\n",
      "Processed 3070/10000\n",
      "Processed 3080/10000\n",
      "Processed 3090/10000\n",
      "Processed 3100/10000\n",
      "Processed 3110/10000\n",
      "Processed 3120/10000\n",
      "Processed 3130/10000\n",
      "Processed 3140/10000\n",
      "Processed 3150/10000\n",
      "Processed 3160/10000\n",
      "Processed 3170/10000\n",
      "Processed 3180/10000\n",
      "Processed 3190/10000\n",
      "Processed 3200/10000\n",
      "Processed 3210/10000\n",
      "Processed 3220/10000\n",
      "Processed 3230/10000\n",
      "Processed 3240/10000\n",
      "Processed 3250/10000\n",
      "Processed 3260/10000\n",
      "Processed 3270/10000\n",
      "Processed 3280/10000\n",
      "Processed 3290/10000\n",
      "Processed 3300/10000\n",
      "Processed 3310/10000\n",
      "Processed 3320/10000\n",
      "Processed 3330/10000\n",
      "Processed 3340/10000\n",
      "Processed 3350/10000\n",
      "Processed 3360/10000\n",
      "Processed 3370/10000\n",
      "Processed 3380/10000\n",
      "Processed 3390/10000\n",
      "Processed 3400/10000\n",
      "Processed 3410/10000\n",
      "Processed 3420/10000\n",
      "Processed 3430/10000\n",
      "Processed 3440/10000\n",
      "Processed 3450/10000\n",
      "Processed 3460/10000\n",
      "Processed 3470/10000\n",
      "Processed 3480/10000\n",
      "Processed 3490/10000\n",
      "Processed 3500/10000\n",
      "Processed 3510/10000\n",
      "Processed 3520/10000\n",
      "Processed 3530/10000\n",
      "Processed 3540/10000\n",
      "Processed 3550/10000\n",
      "Processed 3560/10000\n",
      "Processed 3570/10000\n",
      "Processed 3580/10000\n",
      "Processed 3590/10000\n",
      "Processed 3600/10000\n",
      "Processed 3610/10000\n",
      "Processed 3620/10000\n",
      "Processed 3630/10000\n",
      "Processed 3640/10000\n",
      "Processed 3650/10000\n",
      "Processed 3660/10000\n",
      "Processed 3670/10000\n",
      "Processed 3680/10000\n",
      "Processed 3690/10000\n",
      "Processed 3700/10000\n",
      "Processed 3710/10000\n",
      "Processed 3720/10000\n",
      "Processed 3730/10000\n",
      "Processed 3740/10000\n",
      "Processed 3750/10000\n",
      "Processed 3760/10000\n",
      "Processed 3770/10000\n",
      "Processed 3780/10000\n",
      "Processed 3790/10000\n",
      "Processed 3800/10000\n",
      "Processed 3810/10000\n",
      "Processed 3820/10000\n",
      "Processed 3830/10000\n",
      "Processed 3840/10000\n",
      "Processed 3850/10000\n",
      "Processed 3860/10000\n",
      "Processed 3870/10000\n",
      "Processed 3880/10000\n",
      "Processed 3890/10000\n",
      "Processed 3900/10000\n",
      "Processed 3910/10000\n",
      "Processed 3920/10000\n",
      "Processed 3930/10000\n",
      "Processed 3940/10000\n",
      "Processed 3950/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3960/10000\n",
      "Processed 3970/10000\n",
      "Processed 3980/10000\n",
      "Processed 3990/10000\n",
      "Processed 4000/10000\n",
      "Processed 4010/10000\n",
      "Processed 4020/10000\n",
      "Processed 4030/10000\n",
      "Processed 4040/10000\n",
      "Processed 4050/10000\n",
      "Processed 4060/10000\n",
      "Processed 4070/10000\n",
      "Processed 4080/10000\n",
      "Processed 4090/10000\n",
      "Processed 4100/10000\n",
      "Processed 4110/10000\n",
      "Processed 4120/10000\n",
      "Processed 4130/10000\n",
      "Processed 4140/10000\n",
      "Processed 4150/10000\n",
      "Processed 4160/10000\n",
      "Processed 4170/10000\n",
      "Processed 4180/10000\n",
      "Processed 4190/10000\n",
      "Processed 4200/10000\n",
      "Processed 4210/10000\n",
      "Processed 4220/10000\n",
      "Processed 4230/10000\n",
      "Processed 4240/10000\n",
      "Processed 4250/10000\n",
      "Processed 4260/10000\n",
      "Processed 4270/10000\n",
      "Processed 4280/10000\n",
      "Processed 4290/10000\n",
      "Processed 4300/10000\n",
      "Processed 4310/10000\n",
      "Processed 4320/10000\n",
      "Processed 4330/10000\n",
      "Processed 4340/10000\n",
      "Processed 4350/10000\n",
      "Processed 4360/10000\n",
      "Processed 4370/10000\n",
      "Processed 4380/10000\n",
      "Processed 4390/10000\n",
      "Processed 4400/10000\n",
      "Processed 4410/10000\n",
      "Processed 4420/10000\n",
      "Processed 4430/10000\n",
      "Processed 4440/10000\n",
      "Processed 4450/10000\n",
      "Processed 4460/10000\n",
      "Processed 4470/10000\n",
      "Processed 4480/10000\n",
      "Processed 4490/10000\n",
      "Processed 4500/10000\n",
      "Processed 4510/10000\n",
      "Processed 4520/10000\n",
      "Processed 4530/10000\n",
      "Processed 4540/10000\n",
      "Processed 4550/10000\n",
      "Processed 4560/10000\n",
      "Processed 4570/10000\n",
      "Processed 4580/10000\n",
      "Processed 4590/10000\n",
      "Processed 4600/10000\n",
      "Processed 4610/10000\n",
      "Processed 4620/10000\n",
      "Processed 4630/10000\n",
      "Processed 4640/10000\n",
      "Processed 4650/10000\n",
      "Processed 4660/10000\n",
      "Processed 4670/10000\n",
      "Processed 4680/10000\n",
      "Processed 4690/10000\n",
      "Processed 4700/10000\n",
      "Processed 4710/10000\n",
      "Processed 4720/10000\n",
      "Processed 4730/10000\n",
      "Processed 4740/10000\n",
      "Processed 4750/10000\n",
      "Processed 4760/10000\n",
      "Processed 4770/10000\n",
      "Processed 4780/10000\n",
      "Processed 4790/10000\n",
      "Processed 4800/10000\n",
      "Processed 4810/10000\n",
      "Processed 4820/10000\n",
      "Processed 4830/10000\n",
      "Processed 4840/10000\n",
      "Processed 4850/10000\n",
      "Processed 4860/10000\n",
      "Processed 4870/10000\n",
      "Processed 4880/10000\n",
      "Processed 4890/10000\n",
      "Processed 4900/10000\n",
      "Processed 4910/10000\n",
      "Processed 4920/10000\n",
      "Processed 4930/10000\n",
      "Processed 4940/10000\n",
      "Processed 4950/10000\n",
      "Processed 4960/10000\n",
      "Processed 4970/10000\n",
      "Processed 4980/10000\n",
      "Processed 4990/10000\n",
      "Processed 5000/10000\n",
      "Processed 5010/10000\n",
      "Processed 5020/10000\n",
      "Processed 5030/10000\n",
      "Processed 5040/10000\n",
      "Processed 5050/10000\n",
      "Processed 5060/10000\n",
      "Processed 5070/10000\n",
      "Processed 5080/10000\n",
      "Processed 5090/10000\n",
      "Processed 5100/10000\n",
      "Processed 5110/10000\n",
      "Processed 5120/10000\n",
      "Processed 5130/10000\n",
      "Processed 5140/10000\n",
      "Processed 5150/10000\n",
      "Processed 5160/10000\n",
      "Processed 5170/10000\n",
      "Processed 5180/10000\n",
      "Processed 5190/10000\n",
      "Processed 5200/10000\n",
      "Processed 5210/10000\n",
      "Processed 5220/10000\n",
      "Processed 5230/10000\n",
      "Processed 5240/10000\n",
      "Processed 5250/10000\n",
      "Processed 5260/10000\n",
      "Processed 5270/10000\n",
      "Processed 5280/10000\n",
      "Processed 5290/10000\n",
      "Processed 5300/10000\n",
      "Processed 5310/10000\n",
      "Processed 5320/10000\n",
      "Processed 5330/10000\n",
      "Processed 5340/10000\n",
      "Processed 5350/10000\n",
      "Processed 5360/10000\n",
      "Processed 5370/10000\n",
      "Processed 5380/10000\n",
      "Processed 5390/10000\n",
      "Processed 5400/10000\n",
      "Processed 5410/10000\n",
      "Processed 5420/10000\n",
      "Processed 5430/10000\n",
      "Processed 5440/10000\n",
      "Processed 5450/10000\n",
      "Processed 5460/10000\n",
      "Processed 5470/10000\n",
      "Processed 5480/10000\n",
      "Processed 5490/10000\n",
      "Processed 5500/10000\n",
      "Processed 5510/10000\n",
      "Processed 5520/10000\n",
      "Processed 5530/10000\n",
      "Processed 5540/10000\n",
      "Processed 5550/10000\n",
      "Processed 5560/10000\n",
      "Processed 5570/10000\n",
      "Processed 5580/10000\n",
      "Processed 5590/10000\n",
      "Processed 5600/10000\n",
      "Processed 5610/10000\n",
      "Processed 5620/10000\n",
      "Processed 5630/10000\n",
      "Processed 5640/10000\n",
      "Processed 5650/10000\n",
      "Processed 5660/10000\n",
      "Processed 5670/10000\n",
      "Processed 5680/10000\n",
      "Processed 5690/10000\n",
      "Processed 5700/10000\n",
      "Processed 5710/10000\n",
      "Processed 5720/10000\n",
      "Processed 5730/10000\n",
      "Processed 5740/10000\n",
      "Processed 5750/10000\n",
      "Processed 5760/10000\n",
      "Processed 5770/10000\n",
      "Processed 5780/10000\n",
      "Processed 5790/10000\n",
      "Processed 5800/10000\n",
      "Processed 5810/10000\n",
      "Processed 5820/10000\n",
      "Processed 5830/10000\n",
      "Processed 5840/10000\n",
      "Processed 5850/10000\n",
      "Processed 5860/10000\n",
      "Processed 5870/10000\n",
      "Processed 5880/10000\n",
      "Processed 5890/10000\n",
      "Processed 5900/10000\n",
      "Processed 5910/10000\n",
      "Processed 5920/10000\n",
      "Processed 5930/10000\n",
      "Processed 5940/10000\n",
      "Processed 5950/10000\n",
      "Processed 5960/10000\n",
      "Processed 5970/10000\n",
      "Processed 5980/10000\n",
      "Processed 5990/10000\n",
      "Processed 6000/10000\n",
      "Processed 6010/10000\n",
      "Processed 6020/10000\n",
      "Processed 6030/10000\n",
      "Processed 6040/10000\n",
      "Processed 6050/10000\n",
      "Processed 6060/10000\n",
      "Processed 6070/10000\n",
      "Processed 6080/10000\n",
      "Processed 6090/10000\n",
      "Processed 6100/10000\n",
      "Processed 6110/10000\n",
      "Processed 6120/10000\n",
      "Processed 6130/10000\n",
      "Processed 6140/10000\n",
      "Processed 6150/10000\n",
      "Processed 6160/10000\n",
      "Processed 6170/10000\n",
      "Processed 6180/10000\n",
      "Processed 6190/10000\n",
      "Processed 6200/10000\n",
      "Processed 6210/10000\n",
      "Processed 6220/10000\n",
      "Processed 6230/10000\n",
      "Processed 6240/10000\n",
      "Processed 6250/10000\n",
      "Processed 6260/10000\n",
      "Processed 6270/10000\n",
      "Processed 6280/10000\n",
      "Processed 6290/10000\n",
      "Processed 6300/10000\n",
      "Processed 6310/10000\n",
      "Processed 6320/10000\n",
      "Processed 6330/10000\n",
      "Processed 6340/10000\n",
      "Processed 6350/10000\n",
      "Processed 6360/10000\n",
      "Processed 6370/10000\n",
      "Processed 6380/10000\n",
      "Processed 6390/10000\n",
      "Processed 6400/10000\n",
      "Processed 6410/10000\n",
      "Processed 6420/10000\n",
      "Processed 6430/10000\n",
      "Processed 6440/10000\n",
      "Processed 6450/10000\n",
      "Processed 6460/10000\n",
      "Processed 6470/10000\n",
      "Processed 6480/10000\n",
      "Processed 6490/10000\n",
      "Processed 6500/10000\n",
      "Processed 6510/10000\n",
      "Processed 6520/10000\n",
      "Processed 6530/10000\n",
      "Processed 6540/10000\n",
      "Processed 6550/10000\n",
      "Processed 6560/10000\n",
      "Processed 6570/10000\n",
      "Processed 6580/10000\n",
      "Processed 6590/10000\n",
      "Processed 6600/10000\n",
      "Processed 6610/10000\n",
      "Processed 6620/10000\n",
      "Processed 6630/10000\n",
      "Processed 6640/10000\n",
      "Processed 6650/10000\n",
      "Processed 6660/10000\n",
      "Processed 6670/10000\n",
      "Processed 6680/10000\n",
      "Processed 6690/10000\n",
      "Processed 6700/10000\n",
      "Processed 6710/10000\n",
      "Processed 6720/10000\n",
      "Processed 6730/10000\n",
      "Processed 6740/10000\n",
      "Processed 6750/10000\n",
      "Processed 6760/10000\n",
      "Processed 6770/10000\n",
      "Processed 6780/10000\n",
      "Processed 6790/10000\n",
      "Processed 6800/10000\n",
      "Processed 6810/10000\n",
      "Processed 6820/10000\n",
      "Processed 6830/10000\n",
      "Processed 6840/10000\n",
      "Processed 6850/10000\n",
      "Processed 6860/10000\n",
      "Processed 6870/10000\n",
      "Processed 6880/10000\n",
      "Processed 6890/10000\n",
      "Processed 6900/10000\n",
      "Processed 6910/10000\n",
      "Processed 6920/10000\n",
      "Processed 6930/10000\n",
      "Processed 6940/10000\n",
      "Processed 6950/10000\n",
      "Processed 6960/10000\n",
      "Processed 6970/10000\n",
      "Processed 6980/10000\n",
      "Processed 6990/10000\n",
      "Processed 7000/10000\n",
      "Processed 7010/10000\n",
      "Processed 7020/10000\n",
      "Processed 7030/10000\n",
      "Processed 7040/10000\n",
      "Processed 7050/10000\n",
      "Processed 7060/10000\n",
      "Processed 7070/10000\n",
      "Processed 7080/10000\n",
      "Processed 7090/10000\n",
      "Processed 7100/10000\n",
      "Processed 7110/10000\n",
      "Processed 7120/10000\n",
      "Processed 7130/10000\n",
      "Processed 7140/10000\n",
      "Processed 7150/10000\n",
      "Processed 7160/10000\n",
      "Processed 7170/10000\n",
      "Processed 7180/10000\n",
      "Processed 7190/10000\n",
      "Processed 7200/10000\n",
      "Processed 7210/10000\n",
      "Processed 7220/10000\n",
      "Processed 7230/10000\n",
      "Processed 7240/10000\n",
      "Processed 7250/10000\n",
      "Processed 7260/10000\n",
      "Processed 7270/10000\n",
      "Processed 7280/10000\n",
      "Processed 7290/10000\n",
      "Processed 7300/10000\n",
      "Processed 7310/10000\n",
      "Processed 7320/10000\n",
      "Processed 7330/10000\n",
      "Processed 7340/10000\n",
      "Processed 7350/10000\n",
      "Processed 7360/10000\n",
      "Processed 7370/10000\n",
      "Processed 7380/10000\n",
      "Processed 7390/10000\n",
      "Processed 7400/10000\n",
      "Processed 7410/10000\n",
      "Processed 7420/10000\n",
      "Processed 7430/10000\n",
      "Processed 7440/10000\n",
      "Processed 7450/10000\n",
      "Processed 7460/10000\n",
      "Processed 7470/10000\n",
      "Processed 7480/10000\n",
      "Processed 7490/10000\n",
      "Processed 7500/10000\n",
      "Processed 7510/10000\n",
      "Processed 7520/10000\n",
      "Processed 7530/10000\n",
      "Processed 7540/10000\n",
      "Processed 7550/10000\n",
      "Processed 7560/10000\n",
      "Processed 7570/10000\n",
      "Processed 7580/10000\n",
      "Processed 7590/10000\n",
      "Processed 7600/10000\n",
      "Processed 7610/10000\n",
      "Processed 7620/10000\n",
      "Processed 7630/10000\n",
      "Processed 7640/10000\n",
      "Processed 7650/10000\n",
      "Processed 7660/10000\n",
      "Processed 7670/10000\n",
      "Processed 7680/10000\n",
      "Processed 7690/10000\n",
      "Processed 7700/10000\n",
      "Processed 7710/10000\n",
      "Processed 7720/10000\n",
      "Processed 7730/10000\n",
      "Processed 7740/10000\n",
      "Processed 7750/10000\n",
      "Processed 7760/10000\n",
      "Processed 7770/10000\n",
      "Processed 7780/10000\n",
      "Processed 7790/10000\n",
      "Processed 7800/10000\n",
      "Processed 7810/10000\n",
      "Processed 7820/10000\n",
      "Processed 7830/10000\n",
      "Processed 7840/10000\n",
      "Processed 7850/10000\n",
      "Processed 7860/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7870/10000\n",
      "Processed 7880/10000\n",
      "Processed 7890/10000\n",
      "Processed 7900/10000\n",
      "Processed 7910/10000\n",
      "Processed 7920/10000\n",
      "Processed 7930/10000\n",
      "Processed 7940/10000\n",
      "Processed 7950/10000\n",
      "Processed 7960/10000\n",
      "Processed 7970/10000\n",
      "Processed 7980/10000\n",
      "Processed 7990/10000\n",
      "Processed 8000/10000\n",
      "Processed 8010/10000\n",
      "Processed 8020/10000\n",
      "Processed 8030/10000\n",
      "Processed 8040/10000\n",
      "Processed 8050/10000\n",
      "Processed 8060/10000\n",
      "Processed 8070/10000\n",
      "Processed 8080/10000\n",
      "Processed 8090/10000\n",
      "Processed 8100/10000\n",
      "Processed 8110/10000\n",
      "Processed 8120/10000\n",
      "Processed 8130/10000\n",
      "Processed 8140/10000\n",
      "Processed 8150/10000\n",
      "Processed 8160/10000\n",
      "Processed 8170/10000\n",
      "Processed 8180/10000\n",
      "Processed 8190/10000\n",
      "Processed 8200/10000\n",
      "Processed 8210/10000\n",
      "Processed 8220/10000\n",
      "Processed 8230/10000\n",
      "Processed 8240/10000\n",
      "Processed 8250/10000\n",
      "Processed 8260/10000\n",
      "Processed 8270/10000\n",
      "Processed 8280/10000\n",
      "Processed 8290/10000\n",
      "Processed 8300/10000\n",
      "Processed 8310/10000\n",
      "Processed 8320/10000\n",
      "Processed 8330/10000\n",
      "Processed 8340/10000\n",
      "Processed 8350/10000\n",
      "Processed 8360/10000\n",
      "Processed 8370/10000\n",
      "Processed 8380/10000\n",
      "Processed 8390/10000\n",
      "Processed 8400/10000\n",
      "Processed 8410/10000\n",
      "Processed 8420/10000\n",
      "Processed 8430/10000\n",
      "Processed 8440/10000\n",
      "Processed 8450/10000\n",
      "Processed 8460/10000\n",
      "Processed 8470/10000\n",
      "Processed 8480/10000\n",
      "Processed 8490/10000\n",
      "Processed 8500/10000\n",
      "Processed 8510/10000\n",
      "Processed 8520/10000\n",
      "Processed 8530/10000\n",
      "Processed 8540/10000\n",
      "Processed 8550/10000\n",
      "Processed 8560/10000\n",
      "Processed 8570/10000\n",
      "Processed 8580/10000\n",
      "Processed 8590/10000\n",
      "Processed 8600/10000\n",
      "Processed 8610/10000\n",
      "Processed 8620/10000\n",
      "Processed 8630/10000\n",
      "Processed 8640/10000\n",
      "Processed 8650/10000\n",
      "Processed 8660/10000\n",
      "Processed 8670/10000\n",
      "Processed 8680/10000\n",
      "Processed 8690/10000\n",
      "Processed 8700/10000\n",
      "Processed 8710/10000\n",
      "Processed 8720/10000\n",
      "Processed 8730/10000\n",
      "Processed 8740/10000\n",
      "Processed 8750/10000\n",
      "Processed 8760/10000\n",
      "Processed 8770/10000\n",
      "Processed 8780/10000\n",
      "Processed 8790/10000\n",
      "Processed 8800/10000\n",
      "Processed 8810/10000\n",
      "Processed 8820/10000\n",
      "Processed 8830/10000\n",
      "Processed 8840/10000\n",
      "Processed 8850/10000\n",
      "Processed 8860/10000\n",
      "Processed 8870/10000\n",
      "Processed 8880/10000\n",
      "Processed 8890/10000\n",
      "Processed 8900/10000\n",
      "Processed 8910/10000\n",
      "Processed 8920/10000\n",
      "Processed 8930/10000\n",
      "Processed 8940/10000\n",
      "Processed 8950/10000\n",
      "Processed 8960/10000\n",
      "Processed 8970/10000\n",
      "Processed 8980/10000\n",
      "Processed 8990/10000\n",
      "Processed 9000/10000\n",
      "Processed 9010/10000\n",
      "Processed 9020/10000\n",
      "Processed 9030/10000\n",
      "Processed 9040/10000\n",
      "Processed 9050/10000\n",
      "Processed 9060/10000\n",
      "Processed 9070/10000\n",
      "Processed 9080/10000\n",
      "Processed 9090/10000\n",
      "Processed 9100/10000\n",
      "Processed 9110/10000\n",
      "Processed 9120/10000\n",
      "Processed 9130/10000\n",
      "Processed 9140/10000\n",
      "Processed 9150/10000\n",
      "Processed 9160/10000\n",
      "Processed 9170/10000\n",
      "Processed 9180/10000\n",
      "Processed 9190/10000\n",
      "Processed 9200/10000\n",
      "Processed 9210/10000\n",
      "Processed 9220/10000\n",
      "Processed 9230/10000\n",
      "Processed 9240/10000\n",
      "Processed 9250/10000\n",
      "Processed 9260/10000\n",
      "Processed 9270/10000\n",
      "Processed 9280/10000\n",
      "Processed 9290/10000\n",
      "Processed 9300/10000\n",
      "Processed 9310/10000\n",
      "Processed 9320/10000\n",
      "Processed 9330/10000\n",
      "Processed 9340/10000\n",
      "Processed 9350/10000\n",
      "Processed 9360/10000\n",
      "Processed 9370/10000\n",
      "Processed 9380/10000\n",
      "Processed 9390/10000\n",
      "Processed 9400/10000\n",
      "Processed 9410/10000\n",
      "Processed 9420/10000\n",
      "Processed 9430/10000\n",
      "Processed 9440/10000\n",
      "Processed 9450/10000\n",
      "Processed 9460/10000\n",
      "Processed 9470/10000\n",
      "Processed 9480/10000\n",
      "Processed 9490/10000\n",
      "Processed 9500/10000\n",
      "Processed 9510/10000\n",
      "Processed 9520/10000\n",
      "Processed 9530/10000\n",
      "Processed 9540/10000\n",
      "Processed 9550/10000\n",
      "Processed 9560/10000\n",
      "Processed 9570/10000\n",
      "Processed 9580/10000\n",
      "Processed 9590/10000\n",
      "Processed 9600/10000\n",
      "Processed 9610/10000\n",
      "Processed 9620/10000\n",
      "Processed 9630/10000\n",
      "Processed 9640/10000\n",
      "Processed 9650/10000\n",
      "Processed 9660/10000\n",
      "Processed 9670/10000\n",
      "Processed 9680/10000\n",
      "Processed 9690/10000\n",
      "Processed 9700/10000\n",
      "Processed 9710/10000\n",
      "Processed 9720/10000\n",
      "Processed 9730/10000\n",
      "Processed 9740/10000\n",
      "Processed 9750/10000\n",
      "Processed 9760/10000\n",
      "Processed 9770/10000\n",
      "Processed 9780/10000\n",
      "Processed 9790/10000\n",
      "Processed 9800/10000\n",
      "Processed 9810/10000\n",
      "Processed 9820/10000\n",
      "Processed 9830/10000\n",
      "Processed 9840/10000\n",
      "Processed 9850/10000\n",
      "Processed 9860/10000\n",
      "Processed 9870/10000\n",
      "Processed 9880/10000\n",
      "Processed 9890/10000\n",
      "Processed 9900/10000\n",
      "Processed 9910/10000\n",
      "Processed 9920/10000\n",
      "Processed 9930/10000\n",
      "Processed 9940/10000\n",
      "Processed 9950/10000\n",
      "Processed 9960/10000\n",
      "Processed 9970/10000\n",
      "Processed 9980/10000\n",
      "Processed 9990/10000\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(8)\n",
    "IMAGES_FOLDER = '/home/gulan_filip/Downloads/set/test_set'\n",
    "CSV_PATH = \"./results.csv\"\n",
    "\n",
    "# TODO Add batching\n",
    "results = []\n",
    "images = sorted([(x, int(x.split(\".\")[0])) for x in os.listdir(IMAGES_FOLDER)], key=lambda x: x[1])\n",
    "\n",
    "for ind, (img, _) in enumerate(images):\n",
    "    with open(os.path.join(IMAGES_FOLDER, img), 'rb') as f:\n",
    "        image = Image.open(f).convert(\"RGB\")\n",
    "        \n",
    "    # make example a torch tensor\n",
    "    value = test_transform(image)\n",
    "\n",
    "    test_value = value.unsqueeze(0)\n",
    "    test_value = Variable(test_value)\n",
    "    if USE_GPU:\n",
    "        test_value = test_value.cuda(0)\n",
    "    \n",
    "\n",
    "    \n",
    "    prediction = model_sigmoid(test_value)[0]\n",
    "    prediction = F.sigmoid(prediction)\n",
    "\n",
    "    # get the result out and reshape it\n",
    "    sigmoid = prediction.cpu().data.numpy().flatten()\n",
    "    if sigmoid[0] > 0.5:\n",
    "        name = 'Other'\n",
    "    else:\n",
    "        prediction = model_softmax(test_value)[0].max(1)[1].cpu().data.numpy()[0]\n",
    "        # Get names dicitonary\n",
    "        name = class_dict[prediction]\n",
    "    results.append(name)\n",
    "        \n",
    "#     output = model_softmax(test_value)[0]\n",
    "#     output = F.softmax(output)\n",
    "#     if output.max().cpu().data.numpy() < 0.99:\n",
    "#         name = 'Other'\n",
    "#     else:      \n",
    "#         prediction = output.max(1)[1].cpu().data.numpy()[0]\n",
    "#         # Get names dicitonary\n",
    "#         name = class_dict[prediction]\n",
    "#     results.append(name)\n",
    "\n",
    "        \n",
    "    if ind % 10 == 0:\n",
    "        print(\"Processed {}/{}\".format(ind, len(images)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smiths',\n",
       " 'Target',\n",
       " 'Other',\n",
       " 'Target',\n",
       " 'ShopRite',\n",
       " 'Walgreens',\n",
       " 'HarrisTeeter',\n",
       " 'Other',\n",
       " 'WinCoFoods',\n",
       " 'Target']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "with open(CSV_PATH, \"w\") as f:\n",
    "    for i, line in enumerate(results):\n",
    "        f.write(line)\n",
    "        if i < len(results) - 1:\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
