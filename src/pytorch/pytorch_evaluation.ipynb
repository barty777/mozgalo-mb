{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from data import crop_upper_part, BinaryDataset\n",
    "from model import SqueezeModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED_TEST_DATASET = '/Users/filipgulan/college/test'\n",
    "CPU_CORES = 4\n",
    "BATCH_SIZE = 32\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS REQUIRES THE master branch of the `torchivsion` package\n",
    "def data_transformations(input_shape, crop_perc = 0.5):\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(lambda x: crop_upper_part(np.array(x), crop_perc)),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def var(tensor, volatile=False):\n",
    "    if USE_GPU:\n",
    "        tensor = tensor.cuda(0)\n",
    "    return Variable(tensor, volatile=volatile)\n",
    "\n",
    "def test_sigmoid(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for i, test_batch in enumerate(test_loader):\n",
    "        test_x, test_y = (var(test_batch[0], volatile=True),\n",
    "                          var(test_batch[1], volatile=True))\n",
    "        logit = model(test_x)\n",
    "        \n",
    "        softmax = F.sigmoid(logit).cpu().data.numpy()\n",
    "        ground_truths.extend(test_y.cpu().data.numpy())\n",
    "        \n",
    "        for act in softmax:\n",
    "            predictions.append(act)\n",
    "       \n",
    "        print('Predicting batch {}/{}'.format(i + 1, len(test_loader)), end=\"\\r\", flush=True)\n",
    "        \n",
    "    return np.array(predictions), np.array(ground_truths)\n",
    "\n",
    "\n",
    "def test_softmax(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for i, test_batch in enumerate(test_loader):\n",
    "        test_x, test_y = (var(test_batch[0], volatile=True),\n",
    "                          var(test_batch[1], volatile=True))\n",
    "        logit = model(test_x)\n",
    "        \n",
    "        softmax = F.softmax(logit, dim=0).cpu().data.numpy()\n",
    "        ground_truths.extend(test_y.cpu().data.numpy())\n",
    "        \n",
    "        for act in softmax:\n",
    "            predictions.append(act)\n",
    "       \n",
    "        print('Predicting batch {}/{}'.format(i + 1, len(test_loader)), end=\"\\r\", flush=True)\n",
    "        \n",
    "    return np.array(predictions), np.array(ground_truths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: ./outdir/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipgulan/college/mozgalo-mb/src/pytorch/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/Users/filipgulan/college/mozgalo-mb/src/pytorch/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Load sigmoid model\n",
    "NUM_CLASSES = 26\n",
    "MODEL_PATH = \"./outdir/model\"\n",
    "\n",
    "model_sigmoid = SqueezeModel(fine_tune=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "model_sigmoid.load_state_dict(torch.load(MODEL_PATH, map_location=lambda storage, loc: storage))\n",
    "print(\"Loaded model from:\", MODEL_PATH)\n",
    "model_sigmoid.eval()\n",
    "\n",
    "if USE_GPU:\n",
    "    model_sigmoid.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: ./outdir/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipgulan/college/mozgalo-mb/src/pytorch/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight.data)\n",
      "/Users/filipgulan/college/mozgalo-mb/src/pytorch/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, mean=0.0, std=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Load softmax model\n",
    "NUM_CLASSES = 26\n",
    "MODEL_PATH = \"./outdir/model\"\n",
    "\n",
    "model_softmax = SqueezeModel(fine_tune=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "model_softmax.load_state_dict(torch.load(MODEL_PATH, map_location=lambda storage, loc: storage))\n",
    "print(\"Loaded model from:\", MODEL_PATH)\n",
    "model_softmax.eval()\n",
    "\n",
    "if USE_GPU:\n",
    "    model_softmax.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = data_transformations((3, 299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/filipgulan/college/test/Other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5bf1325e77f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mANNOTATED_TEST_DATASET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m test_dataset_loader_binary = torch.utils.data.DataLoader(test_dataset_binary,\n\u001b[1;32m      3\u001b[0m                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     num_workers=CPU_CORES)\n",
      "\u001b[0;32m~/college/mozgalo-mb/src/pytorch/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, images_dir, other_folder_name, transform)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         self.neg_images = [os.path.join(negative_folder, img) for img in\n\u001b[0;32m---> 62\u001b[0;31m                            os.listdir(negative_folder) if not img.startswith(\".\")]\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_images\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/filipgulan/college/test/Other'"
     ]
    }
   ],
   "source": [
    "test_dataset_binary = BinaryDataset(images_dir=ANNOTATED_TEST_DATASET, transform=test_transform)\n",
    "test_dataset_loader_binary = torch.utils.data.DataLoader(test_dataset_binary,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=CPU_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_softmax = datasets.ImageFolder(root=ANNOTATED_TEST_DATASET, transform=test_transform)\n",
    "test_dataset_loader_softmax = torch.utils.data.DataLoader(test_dataset_softmax,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=CPU_CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other vs. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch 313/313\r"
     ]
    }
   ],
   "source": [
    "pred, true = test_sigmoid(model_sigmoid, test_dataset_loader_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.99      0.97      5009\n",
      "        1.0       0.99      0.95      0.97      4991\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thr = 0.5\n",
    "sigmoid_classes = np.copy(pred)\n",
    "sigmoid_classes[pred > thr] = 1\n",
    "sigmoid_classes[pred <= thr] = 0\n",
    "\n",
    "report = metrics.classification_report(true, sigmoid_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 class softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c89b7e2b29eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset_loader_softmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-43c2fcde3128>\u001b[0m in \u001b[0;36mtest_softmax\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mground_truths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "pred, true = test_softmax(model_softmax, test_dataset_loader_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.argmax(pred)\n",
    "report = metrics.classification_report(correct, true)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting results for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Albertsons',\n",
       " 1: 'BJs',\n",
       " 2: 'CVSPharmacy',\n",
       " 3: 'Costco',\n",
       " 4: 'FredMeyer',\n",
       " 5: 'Frys',\n",
       " 6: 'HEB',\n",
       " 7: 'HarrisTeeter',\n",
       " 8: 'HyVee',\n",
       " 9: 'JewelOsco',\n",
       " 10: 'KingSoopers',\n",
       " 11: 'Kroger',\n",
       " 12: 'Meijer',\n",
       " 13: 'Other',\n",
       " 14: 'Publix',\n",
       " 15: 'Safeway',\n",
       " 16: 'SamsClub',\n",
       " 17: 'ShopRite',\n",
       " 18: 'Smiths',\n",
       " 19: 'StopShop',\n",
       " 20: 'Target',\n",
       " 21: 'Walgreens',\n",
       " 22: 'Walmart',\n",
       " 23: 'Wegmans',\n",
       " 24: 'WholeFoodsMarket',\n",
       " 25: 'WinCoFoods'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class indices when OTher is present\n",
    "labels = {'Albertsons': 0,\n",
    " 'BJs': 1,\n",
    " 'CVSPharmacy': 2,\n",
    " 'Costco': 3,\n",
    " 'FredMeyer': 4,\n",
    " 'Frys': 5,\n",
    " 'HEB': 6,\n",
    " 'HarrisTeeter': 7,\n",
    " 'HyVee': 8,\n",
    " 'JewelOsco': 9,\n",
    " 'KingSoopers': 10,\n",
    " 'Kroger': 11,\n",
    " 'Meijer': 12,\n",
    " 'Other': 13,\n",
    " 'Publix': 14,\n",
    " 'Safeway': 15,\n",
    " 'SamsClub': 16,\n",
    " 'ShopRite': 17,\n",
    " 'Smiths': 18,\n",
    " 'StopShop': 19,\n",
    " 'Target': 20,\n",
    " 'Walgreens': 21,\n",
    " 'Walmart': 22,\n",
    " 'Wegmans': 23,\n",
    " 'WholeFoodsMarket': 24,\n",
    " 'WinCoFoods': 25}\n",
    "class_dict = {v: k for k, v in labels.items()}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/10000\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(4)\n",
    "IMAGES_FOLDER = \"/Users/filipgulan/college/test/Other\"\n",
    "CSV_PATH = \"/tmp/results.csv\"\n",
    "\n",
    "# TODO Add batching\n",
    "results = []\n",
    "images = sorted([(x, int(x.split(\".\")[0])) for x in os.listdir(IMAGES_FOLDER)], key=lambda x: x[1])\n",
    "\n",
    "for ind, (img, _) in enumerate(images):\n",
    "    with open(os.path.join(IMAGES_FOLDER, img), 'rb') as f:\n",
    "        image = Image.open(f).convert(\"RGB\")\n",
    "        \n",
    "    # make example a torch tensor\n",
    "    value = test_transform(image)\n",
    "\n",
    "    test_value = value.unsqueeze(0)\n",
    "    test_value = Variable(test_value)\n",
    "    if USE_GPU:\n",
    "        test_value = test_value.cuda(0)\n",
    "    \n",
    "    prediction = model_softmax(test_value)[0].max(1)[1].cpu().data.numpy()[0]\n",
    "    # Get names dicitonary\n",
    "    name = class_dict[prediction]\n",
    "    results.append(name)\n",
    "\n",
    "        \n",
    "    if ind % 1000 == 0:\n",
    "        print(\"Processed {}/{}\".format(ind, len(images)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smiths',\n",
       " 'Target',\n",
       " 'Other',\n",
       " 'Smiths',\n",
       " 'ShopRite',\n",
       " 'Walgreens',\n",
       " 'HarrisTeeter',\n",
       " 'Other',\n",
       " 'Safeway',\n",
       " 'Smiths']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "with open(CSV_PATH, \"w\") as f:\n",
    "    for i, line in enumerate(results):\n",
    "        f.write(line)\n",
    "        if i < len(results) - 1:\n",
    "            f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
