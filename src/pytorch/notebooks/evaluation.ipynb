{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from data import crop_upper_part\n",
    "from model import SqueezeModelSoftmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to a PyTorch state dict\n",
    "MODEL_PATH = '../models/26_class_final_all_epoch_48-valLoss_0.01565-valF1_0.99899-testF1_0.99701' \n",
    "NUM_CLASSES = 26\n",
    "INPUT_SHAPE = (3, 370, 400) # C x H x W\n",
    "\n",
    "# path to a non-annotated dataset where all images are in same folder with name: <integer_id>.jpg\n",
    "DATASET_PATH = '../../data/robust_ml_challenge_testset'\n",
    "\n",
    "# path to empty folder (it is not mandatory that it exists) - where annotated dataset will be stored\n",
    "OUTPUT_ANNOTATED_PATH = '../../data/annotated_ds'\n",
    "\n",
    "OUTPUT_CSV_PATH = '../output.csv'\n",
    "\n",
    "NUM_THREADS = 8 # number of threads to use - should be same as number of virtual CPU cores\n",
    "USE_GPU = True # use CUDA related stuff\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    " 'Albertsons': 0,\n",
    " 'BJs': 1,\n",
    " 'CVSPharmacy': 2,\n",
    " 'Costco': 3,\n",
    " 'FredMeyer': 4,\n",
    " 'Frys': 5,\n",
    " 'HEB': 6,\n",
    " 'HarrisTeeter': 7,\n",
    " 'HyVee': 8,\n",
    " 'JewelOsco': 9,\n",
    " 'KingSoopers': 10,\n",
    " 'Kroger': 11,\n",
    " 'Meijer': 12,\n",
    " 'Other': 13,\n",
    " 'Publix': 14,\n",
    " 'Safeway': 15,\n",
    " 'SamsClub': 16,\n",
    " 'ShopRite': 17,\n",
    " 'Smiths': 18,\n",
    " 'StopShop': 19,\n",
    " 'Target': 20,\n",
    " 'Walgreens': 21,\n",
    " 'Walmart': 22,\n",
    " 'Wegmans': 23,\n",
    " 'WholeFoodsMarket': 24,\n",
    " 'WinCoFoods': 25}\n",
    "\n",
    "class_dict = {v: k for k, v in class_labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess_transformations(input_shape, crop_perc = 0.5):\n",
    "    \"\"\"Preprocess object for transforming image to model input\n",
    "\n",
    "    Args:\n",
    "        input_shape: model input shape (channels x height x width)\n",
    "        crop_perc: percent of how much image would be cropped from\n",
    "\n",
    "    Returns:\n",
    "        Composite of transforms objects.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    num_channels, height, width = input_shape\n",
    "    \n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(lambda x: crop_upper_part(np.array(x), crop_perc)),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(num_channels),\n",
    "        transforms.Resize((height, width)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def predict_image(image, model, preprocess_transformations, use_gpu=False):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "        model: Model to predict with\n",
    "        preprocess_transformations: Image preprocessing transformations\n",
    "\n",
    "    Returns:\n",
    "        Model outputs for given image.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    input_image = preprocess_transformations(image)\n",
    "    input_image = input_image.unsqueeze(0)\n",
    "    input_tensor = Variable(input_image)\n",
    "    \n",
    "    if use_gpu:\n",
    "        input_tensor = input_tensor.cuda(0)\n",
    "    \n",
    "    return model(input_tensor).cpu().data.numpy()[0]\n",
    "\n",
    "\n",
    "def list_input_images(images_folder):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        images_folder: Folder with input images with name template: <int_id>.jpg\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: (image_file_name, image_int_id)\n",
    "        \n",
    "    \"\"\"\n",
    "    files = os.listdir(images_folder)\n",
    "    images = []\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        name_components = file.split(\".\")\n",
    "        extension = name_components[1].lower()\n",
    "        \n",
    "        if extension == 'jpg' or extension == 'jpeg':\n",
    "            image_id = int(name_components[0])\n",
    "            images.append((file, image_id))\n",
    "            \n",
    "    return sorted(images, key=lambda x: x[1])\n",
    "\n",
    "\n",
    "def open_image(image_path):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to an image.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image in RGB format.\n",
    "        \n",
    "    \"\"\"\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image = Image.open(f).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "\n",
    "def predicted_store(prediction):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        prediction: Model probability output.\n",
    "        \n",
    "    Returns:\n",
    "        Most probable store (argmax)\n",
    "        \n",
    "    \"\"\"\n",
    "    class_indice = np.argmax(prediction)\n",
    "    return class_dict[class_indice]\n",
    "\n",
    "\n",
    "def print_predicted_store_stats(predicted_stores):\n",
    "    unique, counts = np.unique(predicted_stores, return_counts=True)\n",
    "    stats_dict = dict(zip(unique, counts))\n",
    "    for store, count in stats_dict.items():\n",
    "        print(\"{:<16} => {}\".format(store, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and make predictions (softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SqueezeModelSoftmax(num_classes=NUM_CLASSES)\n",
    "model_state_dict = torch.load(MODEL_PATH, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()\n",
    "torch.set_num_threads(NUM_THREADS)\n",
    "\n",
    "if USE_GPU:\n",
    "    model.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "images = list_input_images(DATASET_PATH)\n",
    "preprocess_transformations = data_preprocess_transformations(INPUT_SHAPE)\n",
    "num_images = len(images)\n",
    "for index, (image_filename, _) in enumerate(images):\n",
    "    \n",
    "    image_path = os.path.join(DATASET_PATH, image_filename)\n",
    "    image = open_image(image_path)\n",
    "    \n",
    "    prediction = predict_image(image, model, preprocess_transformations, USE_GPU)\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    print('Image {}/{}'.format(index + 1, num_images), end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Heuristics \n",
    "\n",
    "def some_heuristic_take_all_outputs(predictions):\n",
    "    return predictions\n",
    "\n",
    "predictions = some_heuristic_take_all_outputs(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make predictions\n",
    "\n",
    "predicted_stores = [predicted_store(prediction) for prediction in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and annotate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted stores to CSV\n",
    "\n",
    "with open(OUTPUT_CSV_PATH, \"w\") as f:\n",
    "    for i, store in enumerate(predicted_stores):\n",
    "        f.write(store)\n",
    "        if i < len(predicted_stores) - 1:\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current statistics\n",
    "\n",
    "print_predicted_store_stats(predicted_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate - copy images to new folder - separated by class\n",
    "\n",
    "if not os.path.exists(OUTPUT_ANNOTATED_PATH):\n",
    "    os.makedirs(OUTPUT_ANNOTATED_PATH)\n",
    "    \n",
    "num_stores = len(predicted_stores)\n",
    "    \n",
    "for index, store in enumerate(predicted_stores):\n",
    "    target_folder_path = os.path.join(OUTPUT_ANNOTATED_PATH, store)\n",
    "    if not os.path.exists(target_folder_path):\n",
    "        os.makedirs(target_folder_path)\n",
    "    \n",
    "    filename = str(index) + \".jpg\"\n",
    "    src_file_path = os.path.join(DATASET_PATH, filename)\n",
    "\n",
    "    shutil.copy2(src_file_path, target_folder_path)\n",
    "    print('Image {}/{}'.format(index + 1, num_stores), end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
