{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pytorch.data import crop_upper_part, BinaryDataset\n",
    "from pytorch.model import XCeptionModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED_TEST_DATASET = '../data/test_annotated'\n",
    "CPU_CORES = 8\n",
    "BATCH_SIZE = 32\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS REQUIRES THE master branch of the `torchivsion` package\n",
    "def data_transformations(input_shape, crop_perc = 0.5):\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(lambda x: crop_upper_part(np.array(x), crop_perc)),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize((input_shape[1], input_shape[2])),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def var(tensor, volatile=False):\n",
    "    if USE_GPU:\n",
    "        tensor = tensor.cuda(0)\n",
    "    return Variable(tensor, volatile=volatile)\n",
    "\n",
    "def test_sigmoid(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for i, test_batch in enumerate(test_loader):\n",
    "        test_x, test_y = (var(test_batch[0], volatile=True),\n",
    "                          var(test_batch[1], volatile=True))\n",
    "        logit = model(test_x)\n",
    "        \n",
    "        softmax = F.sigmoid(logit).cpu().data.numpy()\n",
    "        ground_truths.extend(test_y.cpu().data.numpy())\n",
    "        \n",
    "        for act in softmax:\n",
    "            predictions.append(act)\n",
    "       \n",
    "        print('Predicting batch {}/{}'.format(i + 1, len(test_loader)), end=\"\\r\", flush=True)\n",
    "        \n",
    "    return np.array(predictions), np.array(ground_truths)\n",
    "\n",
    "\n",
    "def test_softmax(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for i, test_batch in enumerate(test_loader):\n",
    "        test_x, test_y = (var(test_batch[0], volatile=True),\n",
    "                          var(test_batch[1], volatile=True))\n",
    "        logit = model(test_x)\n",
    "        \n",
    "        softmax = F.softmax(logit, dim=0).cpu().data.numpy()\n",
    "        ground_truths.extend(test_y.cpu().data.numpy())\n",
    "        \n",
    "        for act in softmax:\n",
    "            predictions.append(act)\n",
    "       \n",
    "        print('Predicting batch {}/{}'.format(i + 1, len(test_loader)), end=\"\\r\", flush=True)\n",
    "        \n",
    "    return np.array(predictions), np.array(ground_truths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartol/.virtualenvs/mozgalo/lib/python3.5/site-packages/torch/nn/modules/module.py:514: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  own_state[name].copy_(param)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: ../models/binary_epoch_20-valLoss_0.01741-valAcc_0.99457\n"
     ]
    }
   ],
   "source": [
    "# Load sigmoid model\n",
    "NUM_CLASSES = 1\n",
    "MODEL_PATH = \"../models/binary_epoch_20-valLoss_0.01741-valAcc_0.99457\"\n",
    "\n",
    "model_sigmoid = XCeptionModel(fine_tune=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "\n",
    "model_sigmoid.load_state_dict(torch.load(MODEL_PATH, map_location=lambda storage, loc: storage))\n",
    "print(\"Loaded model from:\", MODEL_PATH)\n",
    "model_sigmoid.eval()\n",
    "\n",
    "if USE_GPU:\n",
    "    model_sigmoid.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: ../models/epoch_07-valLoss_0.00130-valAcc_0.99970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartol/.virtualenvs/mozgalo/lib/python3.5/site-packages/torch/nn/modules/module.py:514: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  own_state[name].copy_(param)\n"
     ]
    }
   ],
   "source": [
    "# Load softmax model\n",
    "NUM_CLASSES = 25\n",
    "MODEL_PATH = \"../models/epoch_07-valLoss_0.00130-valAcc_0.99970\"\n",
    "\n",
    "model_softmax = XCeptionModel(fine_tune=True, num_classes=NUM_CLASSES)\n",
    "\n",
    "model_softmax.load_state_dict(torch.load(MODEL_PATH, map_location=lambda storage, loc: storage))\n",
    "print(\"Loaded model from:\", MODEL_PATH)\n",
    "model_softmax.eval()\n",
    "\n",
    "if USE_GPU:\n",
    "    model_softmax.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = data_transformations(model_softmax.model.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_binary = BinaryDataset(images_dir=ANNOTATED_TEST_DATASET, transform=test_transform)\n",
    "test_dataset_loader_binary = torch.utils.data.DataLoader(test_dataset_binary,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=CPU_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_softmax = datasets.ImageFolder(root=ANNOTATED_TEST_DATASET, transform=test_transform)\n",
    "test_dataset_loader_softmax = torch.utils.data.DataLoader(test_dataset_softmax,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False,\n",
    "                                                    num_workers=CPU_CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other vs. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch 313/313\r"
     ]
    }
   ],
   "source": [
    "pred, true = test_sigmoid(model_sigmoid, test_dataset_loader_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.99      0.97      5009\n",
      "        1.0       0.99      0.95      0.97      4991\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thr = 0.5\n",
    "sigmoid_classes = np.copy(pred)\n",
    "sigmoid_classes[pred > thr] = 1\n",
    "sigmoid_classes[pred <= thr] = 0\n",
    "\n",
    "report = metrics.classification_report(true, sigmoid_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 class softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, true = test_softmax(model_softmax, test_dataset_loader_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.argmax(pred)\n",
    "report = metrics.classification_report(correct, true)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting results for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Albertsons',\n",
       " 1: 'BJs',\n",
       " 2: 'CVSPharmacy',\n",
       " 3: 'Costco',\n",
       " 4: 'FredMeyer',\n",
       " 5: 'Frys',\n",
       " 6: 'HEB',\n",
       " 7: 'HarrisTeeter',\n",
       " 8: 'HyVee',\n",
       " 9: 'JewelOsco',\n",
       " 10: 'KingSoopers',\n",
       " 11: 'Kroger',\n",
       " 12: 'Meijer',\n",
       " 13: 'Publix',\n",
       " 14: 'Safeway',\n",
       " 15: 'SamsClub',\n",
       " 16: 'ShopRite',\n",
       " 17: 'Smiths',\n",
       " 18: 'StopShop',\n",
       " 19: 'Target',\n",
       " 20: 'Walgreens',\n",
       " 21: 'Walmart',\n",
       " 22: 'Wegmans',\n",
       " 23: 'WholeFoodsMarket',\n",
       " 24: 'WinCoFoods'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = [name for name in sorted(os.listdir(ANNOTATED_TEST_DATASET)) if name != \"Other\"]\n",
    "class_dict = {i: name for i, name in enumerate(class_dict)}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/10000\n",
      "Processed 1000/10000\n",
      "Processed 2000/10000\n",
      "Processed 3000/10000\n",
      "Processed 4000/10000\n",
      "Processed 5000/10000\n",
      "Processed 6000/10000\n",
      "Processed 7000/10000\n",
      "Processed 8000/10000\n",
      "Processed 9000/10000\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(8)\n",
    "IMAGES_FOLDER = \"/home/bartol/Projects/mozgalo-mb/src/data/robust_ml_challenge_testset\"\n",
    "CSV_PATH = \"/tmp/results.csv\"\n",
    "\n",
    "# TODO Add batching\n",
    "results = []\n",
    "images = sorted([(x, int(x.split(\".\")[0])) for x in os.listdir(IMAGES_FOLDER)], key=lambda x: x[1])\n",
    "\n",
    "for ind, (img, _) in enumerate(images):\n",
    "    with open(os.path.join(IMAGES_FOLDER, img), 'rb') as f:\n",
    "        image = Image.open(f).convert(\"RGB\")\n",
    "        \n",
    "    # make example a torch tensor\n",
    "    value = test_transform(image)\n",
    "\n",
    "    test_value = value.unsqueeze(0)\n",
    "    test_value = Variable(test_value)\n",
    "    if USE_GPU:\n",
    "        test_value = test_value.cuda(0)\n",
    "\n",
    "    prediction = model_sigmoid(test_value)\n",
    "    prediction = F.sigmoid(prediction)\n",
    "\n",
    "    # get the result out and reshape it\n",
    "    sigmoid = prediction.cpu().data.numpy().flatten()\n",
    "    if sigmoid < 0.5:\n",
    "        results.append(\"Other\")\n",
    "    else:\n",
    "        prediction = model_softmax(test_value).max(1)[1].cpu().data.numpy()[0]\n",
    "        # Get names dicitonary\n",
    "        name = class_dict[prediction]\n",
    "        results.append(name)\n",
    "        \n",
    "    if ind % 1000 == 0:\n",
    "        print(\"Processed {}/{}\".format(ind, len(images)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smiths',\n",
       " 'Target',\n",
       " 'Other',\n",
       " 'Smiths',\n",
       " 'ShopRite',\n",
       " 'Walgreens',\n",
       " 'HarrisTeeter',\n",
       " 'Other',\n",
       " 'Safeway',\n",
       " 'Smiths']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "with open(CSV_PATH, \"w\") as f:\n",
    "    for i, line in enumerate(results):\n",
    "        f.write(line)\n",
    "        if i < len(results) - 1:\n",
    "            f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
