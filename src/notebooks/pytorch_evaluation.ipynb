{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pytorch.data import normalize, crop_upper_part\n",
    "from pytorch.model import LModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATED_TEST_DATASET = '../data/test_annotated'\n",
    "MODEL_PATH = \"../models/epoch_14-valLoss_0.00067-valAcc_1.00000\"\n",
    "CPU_CORES = 6\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 26\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS REQUIRES THE master branch of the `torchivsion` package\n",
    "def data_transformations(input_shape, crop_perc = 0.5):\n",
    "    return transforms.Compose([\n",
    "        transforms.Lambda(lambda x: crop_upper_part(np.array(x), crop_perc)),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.Resize((input_shape[1], input_shape[2])),\n",
    "        transforms.Lambda(lambda x: normalize(np.array(x, dtype=np.float32))),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def var(tensor, volatile=False):\n",
    "    if USE_GPU:\n",
    "        tensor = tensor.cuda(0)\n",
    "    return Variable(tensor, volatile=volatile)\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, ground_truths = [], []\n",
    "    for i, test_batch in enumerate(test_loader):\n",
    "        test_x, test_y = (var(test_batch[0], volatile=True),\n",
    "                          var(test_batch[1], volatile=True))\n",
    "        logit = model(test_x)\n",
    "        \n",
    "        softmax = F.softmax(logit, dim = 0).cpu().data.numpy()\n",
    "        ground_truths.extend(test_y.cpu().data.numpy())\n",
    "        \n",
    "        for act in softmax:\n",
    "            predictions.append(act)\n",
    "       \n",
    "        print('Predicting batch {}/{}'.format(i + 1, len(test_loader)), end=\"\\r\", flush=True)\n",
    "        \n",
    "    return np.array(predictions), ground_truths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: ../models/epoch_14-valLoss_0.00067-valAcc_1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartol/.virtualenvs/mozgalo/lib/python3.5/site-packages/torch/nn/modules/module.py:514: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  own_state[name].copy_(param)\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = LModel(num_classes=NUM_CLASSES, fine_tune=True, margin=1)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=lambda storage, loc: storage))\n",
    "print(\"Loaded model from:\", MODEL_PATH)\n",
    "\n",
    "\n",
    "if USE_GPU:\n",
    "    model.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = data_transformations(model.model.input_size)\n",
    "test_dataset = datasets.ImageFolder(root=ANNOTATED_TEST_DATASET, transform=test_transform)\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    num_workers=CPU_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting batch 313/313\r"
     ]
    }
   ],
   "source": [
    "pred, true = test(model, test_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 4, 25, 22, 25, 25, 10, 25, 25, 3, 5, 24, 25, 9, 20, 2, 10, 23, 19, 25, 1, 25, 2, 25, 25, 25, 3, 25, 23, 0, 25, 25, 20, 25, 21, 25, 19, 25, 25, 25, 25, 13, 24, 3, 2, 25, 25, 25, 25, 20, 25, 10, 25, 14, 25, 15, 25, 25, 25, 25, 23, 18, 12, 25, 19, 25, 25, 20, 25, 1, 25, 7, 9, 25, 3, 25, 1, 25, 24, 9, 7, 17, 25, 11, 25, 25, 25, 12, 25, 25, 23, 12, 25, 25, 0, 25, 9, 25, 25, 25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57844186, 0.9477168 , 0.5854987 , 0.9999529 , 0.08573863,\n",
       "       0.08208578, 0.16463608, 0.04125353, 0.3600355 , 0.04967184,\n",
       "       0.9998759 , 0.999345  , 0.74939835, 0.9998833 , 0.9977604 ,\n",
       "       0.41321862, 0.07723735, 0.99175185, 0.4214487 , 0.05868314,\n",
       "       0.99982446, 0.02958403, 0.58677584, 0.847426  , 0.08206109,\n",
       "       0.2049164 , 0.99843603, 0.16592279, 0.0430133 , 0.9969772 ,\n",
       "       0.21745123, 0.14201131, 0.20205298, 0.07701006, 0.9956423 ,\n",
       "       0.49463594, 0.9999417 , 0.16497746, 0.41928592, 0.0656886 ,\n",
       "       0.07937535, 0.99851674, 0.9996972 , 0.99993956, 0.99995756,\n",
       "       0.13273172, 0.21274583, 0.11977648, 0.07522453, 0.9998869 ,\n",
       "       0.2561855 , 0.65320385, 0.3185851 , 0.97605693, 0.33505952,\n",
       "       0.99741435, 0.07496938, 0.09490413, 0.43003523, 0.03731275,\n",
       "       0.9994991 , 0.9348558 , 0.999551  , 0.6912993 , 0.9995492 ,\n",
       "       0.08941256, 0.21459186, 0.99997234, 0.2554902 , 0.93372065,\n",
       "       0.60944295, 0.10903376, 0.2164551 , 0.04589016, 0.99995375,\n",
       "       0.16703282, 0.07826427, 0.21076357, 0.99999845, 0.78344214,\n",
       "       0.8908761 , 0.9978759 , 0.6687449 , 0.5938324 , 0.28584957,\n",
       "       0.19544037, 0.42617145, 0.5581    , 0.04615891, 0.04821721,\n",
       "       0.9996668 , 0.4418548 , 0.05117255, 0.85106784, 0.9978485 ,\n",
       "       0.9997813 , 0.99992883, 0.6963101 , 0.05842988, 0.0947243 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(true[:100])\n",
    "\n",
    "np.max(pred, 1)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49984625"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.max(pred, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.58      0.71       200\n",
      "          1       1.00      0.60      0.75       200\n",
      "          2       1.00      0.60      0.75       200\n",
      "          3       1.00      0.67      0.80       200\n",
      "          4       0.98      0.65      0.78       198\n",
      "          5       0.99      0.59      0.74       202\n",
      "          6       0.97      0.63      0.76       200\n",
      "          7       0.97      0.56      0.71       200\n",
      "          8       0.96      0.61      0.75       198\n",
      "          9       0.82      0.58      0.68       201\n",
      "         10       1.00      0.36      0.53       198\n",
      "         11       0.97      0.57      0.72       200\n",
      "         12       0.98      0.63      0.77       200\n",
      "         13       0.99      0.68      0.80       198\n",
      "         14       0.98      0.60      0.75       198\n",
      "         15       1.00      0.64      0.78       200\n",
      "         16       0.97      0.61      0.75       207\n",
      "         17       0.98      0.55      0.71       196\n",
      "         18       0.70      0.54      0.61       199\n",
      "         19       0.99      0.57      0.72       200\n",
      "         20       0.99      0.60      0.75       202\n",
      "         21       0.93      0.55      0.69       199\n",
      "         22       0.96      0.67      0.79       198\n",
      "         23       0.98      0.65      0.78       200\n",
      "         24       0.93      0.70      0.80       197\n",
      "         25       0.71      0.97      0.82      5009\n",
      "\n",
      "avg / total       0.83      0.79      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thr = 0.9\n",
    "predicted = []\n",
    "for act in pred:\n",
    "    sort = sorted(act)[::-1]\n",
    "    \n",
    "    if sort[0] < thr:\n",
    "        predicted.append(25)\n",
    "    else:\n",
    "        predicted.append(np.argmax(act))\n",
    "        \n",
    "report = metrics.classification_report(true, predicted)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
